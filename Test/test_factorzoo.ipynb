{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import matplotlib.patches as mpathes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from matplotlib import ticker\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PqiDataSdk import PqiDataSdk\n",
    "\n",
    "ds = PqiDataSdk(user=\"zyding\", size=128, pool_type=\"mt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_zz500 = ds.get_index_weight(ticker='000905').StockTicker.values\n",
    "tickers_zz1000 = ds.get_index_weight(ticker='000852').StockTicker.values\n",
    "tickers_hs300 = ds.get_index_weight(ticker='399300').StockTicker.values\n",
    "\n",
    "tickers_zz1800 = np.concatenate([tickers_hs300, tickers_zz500, tickers_zz1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ds.get_ticker_list(date='all')\n",
    "start_date = '20170101'\n",
    "end_date = '20191231'\n",
    "lst_trade_date = ds.get_trade_dates(start_date=start_date, end_date=end_date)\n",
    "\n",
    "\n",
    "path_FGv3 = '/home/zyding/factor_garden_v3/'\n",
    "lst_FGv3 = [i[:-3] for i in os.listdir(path_FGv3+'eod_feature/')]\n",
    "path_NSF = '/home/zyding/neuron_support_fac/'\n",
    "lst_NSF = [i[:-3] for i in os.listdir(path_NSF+'eod_feature/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_data_FGv3 = ds.get_eod_feature(fields=lst_FGv3,\n",
    "                                      where=path_FGv3,\n",
    "                                      tickers=list(tickers_zz1800),\n",
    "                                      dates=lst_trade_date)\n",
    "factor_data_NSF = ds.get_eod_feature(fields=lst_NSF,\n",
    "                                     where=path_NSF,\n",
    "                                     tickers=list(tickers_zz1800),\n",
    "                                     dates=lst_trade_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "eod_data = ds.get_eod_history(fields=['OpenPrice', 'ClosePrice'], tickers=tickers_zz1800, start_date='20170101',\n",
    "                              end_date='20191231', day_type='trade', price_mode='former')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ret_eod = eod_data['ClosePrice'].apply(lambda x: x/x.shift()-1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = df_ret_eod.stack(dropna=False)\n",
    "y_train = df_ret_eod.shift(-1, axis=1).stack(dropna=False)\n",
    "y_train.name = 'ret'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_idx = factor_data_FGv3[0].to_dataframe().stack(dropna=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_2d(pqidata):\n",
    "    shape = (pqidata.shape[1]*pqidata.shape[2], pqidata.shape[0])\n",
    "    return pqidata.values.transpose((1, 2, 0)).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.concatenate([transform_to_2d(factor_data_FGv3),\n",
    "                         transform_to_2d(factor_data_NSF)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [f'fac_FGv3_{i+1}' for i in range(factor_data_FGv3.shape[0])]+[\n",
    "    f'fac_NSF_{i+1}' for i in range(factor_data_NSF.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 543 µs, sys: 49 µs, total: 592 µs\n",
      "Wall time: 595 µs\n"
     ]
    }
   ],
   "source": [
    "%time X_train = pd.DataFrame(index=X_idx, columns=col, data=X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>fac_FGv3_1</th>\n",
       "      <th>fac_FGv3_2</th>\n",
       "      <th>fac_FGv3_3</th>\n",
       "      <th>fac_FGv3_4</th>\n",
       "      <th>fac_FGv3_5</th>\n",
       "      <th>fac_FGv3_6</th>\n",
       "      <th>fac_FGv3_7</th>\n",
       "      <th>fac_FGv3_8</th>\n",
       "      <th>fac_FGv3_9</th>\n",
       "      <th>fac_FGv3_10</th>\n",
       "      <th>...</th>\n",
       "      <th>fac_NSF_1041</th>\n",
       "      <th>fac_NSF_1042</th>\n",
       "      <th>fac_NSF_1043</th>\n",
       "      <th>fac_NSF_1044</th>\n",
       "      <th>fac_NSF_1045</th>\n",
       "      <th>fac_NSF_1046</th>\n",
       "      <th>fac_NSF_1047</th>\n",
       "      <th>fac_NSF_1048</th>\n",
       "      <th>fac_NSF_1049</th>\n",
       "      <th>fac_NSF_1050</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">600519</th>\n",
       "      <th>20170103</th>\n",
       "      <td>1.332</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.082</td>\n",
       "      <td>...</td>\n",
       "      <td>-56079.912</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-171025.529</td>\n",
       "      <td>-3679384.943</td>\n",
       "      <td>-206417.000</td>\n",
       "      <td>3258770.004</td>\n",
       "      <td>0.045</td>\n",
       "      <td>2358919.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170104</th>\n",
       "      <td>-3.225</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.102</td>\n",
       "      <td>...</td>\n",
       "      <td>-9370937.056</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.962</td>\n",
       "      <td>5.524</td>\n",
       "      <td>482399.174</td>\n",
       "      <td>-14131792.189</td>\n",
       "      <td>789557.810</td>\n",
       "      <td>19937659.792</td>\n",
       "      <td>-0.708</td>\n",
       "      <td>13913257.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170105</th>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.003</td>\n",
       "      <td>1.246</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.093</td>\n",
       "      <td>...</td>\n",
       "      <td>-1446071.934</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.923</td>\n",
       "      <td>7.215</td>\n",
       "      <td>-301959.637</td>\n",
       "      <td>-4885990.260</td>\n",
       "      <td>-241860.840</td>\n",
       "      <td>5199351.114</td>\n",
       "      <td>-1.432</td>\n",
       "      <td>5572031.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170106</th>\n",
       "      <td>1.969</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1.352</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.128</td>\n",
       "      <td>...</td>\n",
       "      <td>-3060222.447</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.385</td>\n",
       "      <td>1.142</td>\n",
       "      <td>-2755.505</td>\n",
       "      <td>-7124068.636</td>\n",
       "      <td>-551635.620</td>\n",
       "      <td>7397897.191</td>\n",
       "      <td>0.630</td>\n",
       "      <td>4625793.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20170109</th>\n",
       "      <td>1.136</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.145</td>\n",
       "      <td>...</td>\n",
       "      <td>-1630085.876</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.385</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>-204788.894</td>\n",
       "      <td>-3368545.452</td>\n",
       "      <td>-258023.500</td>\n",
       "      <td>2636398.288</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>2045580.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">603530</th>\n",
       "      <th>20191225</th>\n",
       "      <td>-0.959</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.082</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>...</td>\n",
       "      <td>95021.754</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>8555.185</td>\n",
       "      <td>-393739.500</td>\n",
       "      <td>14664.000</td>\n",
       "      <td>346885.200</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>217248.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191226</th>\n",
       "      <td>-1.075</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>...</td>\n",
       "      <td>260746.610</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.846</td>\n",
       "      <td>1.225</td>\n",
       "      <td>47512.037</td>\n",
       "      <td>-406219.700</td>\n",
       "      <td>-3188.710</td>\n",
       "      <td>448667.500</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>294257.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191227</th>\n",
       "      <td>-0.916</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.204</td>\n",
       "      <td>-0.444</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.816</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>...</td>\n",
       "      <td>2272.402</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.923</td>\n",
       "      <td>5.103</td>\n",
       "      <td>38977.333</td>\n",
       "      <td>-808952.500</td>\n",
       "      <td>50256.000</td>\n",
       "      <td>552377.600</td>\n",
       "      <td>1.228</td>\n",
       "      <td>544449.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191230</th>\n",
       "      <td>-0.294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-2.121</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>...</td>\n",
       "      <td>107902.364</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.308</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>29452.222</td>\n",
       "      <td>-267698.000</td>\n",
       "      <td>-6046.000</td>\n",
       "      <td>405074.100</td>\n",
       "      <td>0.331</td>\n",
       "      <td>198753.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191231</th>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.422</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-1.871</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>...</td>\n",
       "      <td>249894.860</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.462</td>\n",
       "      <td>6.384</td>\n",
       "      <td>32151.222</td>\n",
       "      <td>-527692.552</td>\n",
       "      <td>87104.000</td>\n",
       "      <td>435714.500</td>\n",
       "      <td>0.238</td>\n",
       "      <td>523542.398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1315800 rows × 1442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fac_FGv3_1  fac_FGv3_2  fac_FGv3_3  fac_FGv3_4  fac_FGv3_5  \\\n",
       "600519 20170103       1.332      -0.000       0.000      -0.320       0.206   \n",
       "       20170104      -3.225      -0.001      -0.000      -0.136      -0.062   \n",
       "       20170105      -0.068      -0.001      -0.000       0.029      -0.013   \n",
       "       20170106       1.969      -0.001      -0.000      -0.179      -0.084   \n",
       "       20170109       1.136      -0.001      -0.000      -0.568      -0.090   \n",
       "...                     ...         ...         ...         ...         ...   \n",
       "603530 20191225      -0.959      -0.001      -0.005      -0.023      -0.401   \n",
       "       20191226      -1.075      -0.000      -0.004      -0.020      -0.452   \n",
       "       20191227      -0.916       0.000      -0.004       0.204      -0.444   \n",
       "       20191230      -0.294       0.000      -0.001       0.064      -0.440   \n",
       "       20191231       0.041      -0.001      -0.001      -0.074      -0.422   \n",
       "\n",
       "                 fac_FGv3_6  fac_FGv3_7  fac_FGv3_8  fac_FGv3_9  fac_FGv3_10  \\\n",
       "600519 20170103       0.003       0.719       0.001      -0.002        0.082   \n",
       "       20170104       0.002       0.831       0.001      -0.002        0.102   \n",
       "       20170105       0.003       1.246       0.002      -0.002        0.093   \n",
       "       20170106       0.004       1.352       0.002      -0.002        0.128   \n",
       "       20170109       0.005       0.998       0.000      -0.002        0.145   \n",
       "...                     ...         ...         ...         ...          ...   \n",
       "603530 20191225       0.003       0.082      -0.000      -0.002       -0.022   \n",
       "       20191226       0.008      -0.537      -0.001      -0.001       -0.024   \n",
       "       20191227       0.006      -0.816      -0.001      -0.002       -0.047   \n",
       "       20191230       0.005      -2.121      -0.001      -0.000       -0.031   \n",
       "       20191231       0.004      -1.871      -0.001       0.001       -0.050   \n",
       "\n",
       "                 ...  fac_NSF_1041  fac_NSF_1042  fac_NSF_1043  fac_NSF_1044  \\\n",
       "600519 20170103  ...    -56079.912         0.731         0.000        -0.073   \n",
       "       20170104  ...  -9370937.056         0.923         0.962         5.524   \n",
       "       20170105  ...  -1446071.934         0.885         0.923         7.215   \n",
       "       20170106  ...  -3060222.447         0.346         0.385         1.142   \n",
       "       20170109  ...  -1630085.876         0.808         0.385        -0.118   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "603530 20191225  ...     95021.754         0.231         0.000         0.748   \n",
       "       20191226  ...    260746.610         0.808         0.846         1.225   \n",
       "       20191227  ...      2272.402         0.885         0.923         5.103   \n",
       "       20191230  ...    107902.364         0.923         0.308        -0.313   \n",
       "       20191231  ...    249894.860         0.423         0.462         6.384   \n",
       "\n",
       "                 fac_NSF_1045  fac_NSF_1046  fac_NSF_1047  fac_NSF_1048  \\\n",
       "600519 20170103   -171025.529  -3679384.943   -206417.000   3258770.004   \n",
       "       20170104    482399.174 -14131792.189    789557.810  19937659.792   \n",
       "       20170105   -301959.637  -4885990.260   -241860.840   5199351.114   \n",
       "       20170106     -2755.505  -7124068.636   -551635.620   7397897.191   \n",
       "       20170109   -204788.894  -3368545.452   -258023.500   2636398.288   \n",
       "...                       ...           ...           ...           ...   \n",
       "603530 20191225      8555.185   -393739.500     14664.000    346885.200   \n",
       "       20191226     47512.037   -406219.700     -3188.710    448667.500   \n",
       "       20191227     38977.333   -808952.500     50256.000    552377.600   \n",
       "       20191230     29452.222   -267698.000     -6046.000    405074.100   \n",
       "       20191231     32151.222   -527692.552     87104.000    435714.500   \n",
       "\n",
       "                 fac_NSF_1049  fac_NSF_1050  \n",
       "600519 20170103         0.045   2358919.481  \n",
       "       20170104        -0.708  13913257.710  \n",
       "       20170105        -1.432   5572031.075  \n",
       "       20170106         0.630   4625793.276  \n",
       "       20170109        -0.229   2045580.347  \n",
       "...                       ...           ...  \n",
       "603530 20191225        -0.408    217248.852  \n",
       "       20191226        -0.063    294257.628  \n",
       "       20191227         1.228    544449.792  \n",
       "       20191230         0.331    198753.472  \n",
       "       20191231         0.238    523542.398  \n",
       "\n",
       "[1315800 rows x 1442 columns]"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train.ret.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[:, df_train.notnull().sum()/len(df_train) > 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(thresh=0.9*df_train.shape[1]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.replace(np.inf, 0).replace(-np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = df_train.drop('ret', axis=1)\n",
    "y_sub = df_train['ret'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = StandardScaler().fit(X_sub).transform(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "    X_sub, y_sub, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet_params = dict(\n",
    "    n_d=128,  # 可以理解为用来决定输出的隐藏层神经元个数。n_d越大，拟合能力越强，也容易过拟合\n",
    "    n_a=128,   # 可以理解为用来决定下一决策步特征选择的隐藏层神经元个数\n",
    "    n_steps=4,  # 决策步的个数。可理解为决策树中分裂结点的次数\n",
    "    gamma=1.2,  # 决定历史所用特征在当前决策步的特征选择阶段的权重，gamma=1时，表示每个特征在所有决策步中至多仅出现1次\n",
    "    lambda_sparse=1e-3,  # 稀疏正则项权重，用来对特征选择阶段的特征稀疏性添加约束,越大则特征选择越稀疏\n",
    "    optimizer_fn=torch.optim.Adam,  # 优化器\n",
    "    optimizer_params=dict(lr=1e-3, weight_decay=1e-5),\n",
    "    mask_type=\"entmax\",\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "reg_tabnet = TabNetRegressor(**tabnet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.71494 | val_0_rmse: 0.04027 |  0:01:31s\n",
      "epoch 1  | loss: 0.00307 | val_0_rmse: 0.02961 |  0:03:03s\n",
      "epoch 2  | loss: 0.00168 | val_0_rmse: 0.02928 |  0:04:33s\n",
      "epoch 3  | loss: 0.00113 | val_0_rmse: 0.02912 |  0:06:05s\n",
      "epoch 4  | loss: 0.00093 | val_0_rmse: 0.02916 |  0:07:36s\n",
      "epoch 5  | loss: 0.00089 | val_0_rmse: 0.0291  |  0:09:07s\n",
      "epoch 6  | loss: 0.00088 | val_0_rmse: 0.02909 |  0:10:38s\n",
      "epoch 7  | loss: 0.00087 | val_0_rmse: 0.02909 |  0:12:09s\n",
      "epoch 8  | loss: 0.00087 | val_0_rmse: 0.02909 |  0:13:41s\n",
      "epoch 9  | loss: 0.00086 | val_0_rmse: 0.02909 |  0:15:11s\n",
      "epoch 10 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:16:42s\n",
      "epoch 11 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:18:13s\n",
      "epoch 12 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:19:44s\n",
      "epoch 13 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:21:16s\n",
      "epoch 14 | loss: 0.00086 | val_0_rmse: 0.02909 |  0:22:47s\n",
      "epoch 15 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:24:19s\n",
      "epoch 16 | loss: 0.00086 | val_0_rmse: 0.02909 |  0:25:50s\n",
      "epoch 17 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:27:22s\n",
      "epoch 18 | loss: 0.00086 | val_0_rmse: 0.02909 |  0:28:53s\n",
      "epoch 19 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:30:24s\n",
      "epoch 20 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:31:55s\n",
      "epoch 21 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:33:25s\n",
      "epoch 22 | loss: 0.00086 | val_0_rmse: 0.02909 |  0:34:56s\n",
      "epoch 23 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:36:26s\n",
      "epoch 24 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:37:58s\n",
      "epoch 25 | loss: 0.00086 | val_0_rmse: 0.02912 |  0:39:29s\n",
      "epoch 26 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:41:00s\n",
      "epoch 27 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:42:31s\n",
      "epoch 28 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:44:02s\n",
      "epoch 29 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:45:33s\n",
      "epoch 30 | loss: 0.00086 | val_0_rmse: 0.0291  |  0:47:04s\n",
      "epoch 31 | loss: 0.00086 | val_0_rmse: 0.02908 |  0:48:36s\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_rmse = 0.02908\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "reg_tabnet.fit(\n",
    "    X_train_sub, y_train_sub.reshape(-1, 1),\n",
    "    eval_set=[(X_val, y_val.reshape(-1, 1))],\n",
    "    eval_metric=['rmse'],\n",
    "    max_epochs=300,  # 最大迭代次数\n",
    "    patience=10,    # 在验证集上早停次数，\n",
    "    batch_size=512,  # BN作用在的输入特征batch\n",
    "    virtual_batch_size=512,  # 除了作用于模型输入特征的第一层BN外，都是用的是ghost BN。\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = dict(max_depth=8,\n",
    "                  learning_rate=0.1,\n",
    "                  eta=0.1,\n",
    "                  n_estimators=1000,\n",
    "                  silent=None,\n",
    "                  objective='reg:squarederror',\n",
    "                  booster='gbtree',\n",
    "                  n_jobs=-1,\n",
    "                  nthread=None,\n",
    "                  gamma=0,\n",
    "                  min_child_weight=1,\n",
    "                  max_delta_step=0,\n",
    "                  subsample=0.8,\n",
    "                  colsample_bytree=1,\n",
    "                  colsample_bylevel=1,\n",
    "                  colsample_bynode=1,\n",
    "                  scale_pos_weight=1,\n",
    "                  base_score=0.5,\n",
    "                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_xgb = XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.45114\n",
      "[10]\tvalidation_0-rmse:0.15960\n",
      "[20]\tvalidation_0-rmse:0.06183\n",
      "[30]\tvalidation_0-rmse:0.03449\n",
      "[40]\tvalidation_0-rmse:0.02946\n",
      "[50]\tvalidation_0-rmse:0.02876\n",
      "[60]\tvalidation_0-rmse:0.02866\n",
      "[70]\tvalidation_0-rmse:0.02862\n",
      "[80]\tvalidation_0-rmse:0.02861\n",
      "[90]\tvalidation_0-rmse:0.02860\n",
      "[100]\tvalidation_0-rmse:0.02857\n",
      "[110]\tvalidation_0-rmse:0.02855\n",
      "[120]\tvalidation_0-rmse:0.02855\n",
      "[130]\tvalidation_0-rmse:0.02855\n",
      "[140]\tvalidation_0-rmse:0.02854\n",
      "[150]\tvalidation_0-rmse:0.02854\n",
      "[160]\tvalidation_0-rmse:0.02854\n",
      "[170]\tvalidation_0-rmse:0.02852\n",
      "[180]\tvalidation_0-rmse:0.02851\n",
      "[190]\tvalidation_0-rmse:0.02851\n",
      "[200]\tvalidation_0-rmse:0.02851\n",
      "[210]\tvalidation_0-rmse:0.02851\n",
      "[220]\tvalidation_0-rmse:0.02851\n",
      "[230]\tvalidation_0-rmse:0.02851\n",
      "[240]\tvalidation_0-rmse:0.02850\n",
      "[250]\tvalidation_0-rmse:0.02850\n",
      "[260]\tvalidation_0-rmse:0.02849\n",
      "[270]\tvalidation_0-rmse:0.02849\n",
      "[280]\tvalidation_0-rmse:0.02849\n",
      "[290]\tvalidation_0-rmse:0.02849\n",
      "[300]\tvalidation_0-rmse:0.02849\n",
      "[310]\tvalidation_0-rmse:0.02849\n",
      "[320]\tvalidation_0-rmse:0.02849\n",
      "[327]\tvalidation_0-rmse:0.02849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, eta=0.1, gamma=0,\n",
       "             gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=1000, n_jobs=-1, nthread=256, num_parallel_tree=1,\n",
       "             random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             silent=None, subsample=0.8, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_xgb.fit(X_train_sub, y_train_sub.reshape(-1, 1),\n",
    "            eval_set=[(X_val, y_val.reshape(-1, 1))],\n",
    "            early_stopping_rounds=40,\n",
    "            verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
